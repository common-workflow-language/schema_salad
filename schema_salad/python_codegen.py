"""Python code generator for a given schema salad definition."""

import textwrap
from collections.abc import MutableSequence
from io import StringIO
from typing import IO, Any, Final

try:
    import black
except ModuleNotFoundError:
    black = None  # type: ignore[assignment]

from importlib.resources import files

from . import schema
from .codegen_base import CodeGenBase, LazyInitDef, TypeDef
from .exceptions import SchemaException
from .schema import shortname

_string_type_def: Final = TypeDef(name="strtype", init="_PrimitiveLoader(str)", instance_type="str")
_int_type_def: Final = TypeDef(name="inttype", init="_PrimitiveLoader(i32)", instance_type="i32")
_long_type_def: Final = TypeDef(name="longtype", init="_PrimitiveLoader(i64)", instance_type="i64")
_float_type_def: Final = TypeDef(
    name="floattype", init="_PrimitiveLoader(float)", instance_type="float"
)
_bool_type_def: Final = TypeDef(
    name="booltype", init="_PrimitiveLoader(bool)", instance_type="bool"
)
_null_type_def: Final = TypeDef(
    name="None_type", init="_PrimitiveLoader(type(None))", instance_type="None"
)
_any_type_def: Final = TypeDef(name="Any_type", init="_AnyLoader()", instance_type="Any")

prims: Final = {
    "http://www.w3.org/2001/XMLSchema#string": _string_type_def,
    "http://www.w3.org/2001/XMLSchema#int": _int_type_def,
    "http://www.w3.org/2001/XMLSchema#long": _int_type_def,
    "http://www.w3.org/2001/XMLSchema#float": _float_type_def,
    "http://www.w3.org/2001/XMLSchema#double": _float_type_def,
    "http://www.w3.org/2001/XMLSchema#boolean": _bool_type_def,
    "https://w3id.org/cwl/salad#null": _null_type_def,
    "https://w3id.org/cwl/salad#Any": _any_type_def,
    "string": _string_type_def,
    "int": _int_type_def,
    "long": _long_type_def,
    "float": _float_type_def,
    "double": _float_type_def,
    "boolean": _bool_type_def,
    "null": _null_type_def,
    "Any": _any_type_def,
}


def fmt(text: str, indent: int) -> str:
    """
    Use black to format this snippet.

    :param indent the indent level for the current context
    """
    if not black:
        raise Exception(
            "Must install 'black' to use the Python code generator. "
            "If installing schema-salad via pip, try `pip install schema-salad[pycodegen]`."
        )
    return textwrap.indent(
        black.format_str(
            text,
            mode=black.mode.Mode(
                target_versions={black.mode.TargetVersion.PY310}, line_length=88 - indent
            ),
        ),
        " " * indent,
    )


class PythonCodeGen(CodeGenBase):
    """Generation of Python code for a given Schema Salad definition."""

    def __init__(
        self,
        out: IO[str],
        copyright: str | None,
        parser_info: str,
        salad_version: str,
    ) -> None:
        super().__init__()
        self.out: Final = out
        self.current_class_is_abstract = False
        self.serializer = StringIO()
        self.idfield = ""
        self.copyright: Final = copyright
        self.parser_info: Final = parser_info
        self.salad_version: Final = salad_version

    @staticmethod
    def safe_name(name: str) -> str:
        """Generate a safe version of the given name."""
        avn = schema.avro_field_name(name)
        if avn.startswith("anon."):
            avn = avn[5:]
        elif avn[0].isdigit():
            avn = f"_{avn}"
        elif avn in ("class", "in", "type"):
            # reserved words
            avn = f"{avn}_"
        return avn.replace(".", "_")

    def prologue(self) -> None:
        """Trigger to generate the prolouge code."""
        self.out.write(
            """#
# This file was autogenerated using schema-salad-tool --codegen=python
# The code itself is released under the Apache 2.0 license and the help text is
# subject to the license of the original schema.
"""
        )
        if self.copyright:
            self.out.write(
                """
#
# The original schema is {copyright}.
""".format(
                    copyright=self.copyright
                )
            )

        python_codegen_support: Final = (
            files("schema_salad").joinpath("python_codegen_support.py").read_text("UTF-8")
        )
        self.out.write(python_codegen_support[python_codegen_support.find("\n") + 1 :])
        self.out.write("\n\n")

        self.out.write(
            f"""def parser_info() -> str:
    return "{self.parser_info}"


"""  # noqa: B907
        )

        for primitive in prims.values():
            self.declare_type(primitive)

    def begin_class(
        self,  # pylint: disable=too-many-arguments
        classname: str,
        extends: MutableSequence[str],
        doc: str,
        abstract: bool,
        field_names: MutableSequence[str],
        idfield: str,
        optional_fields: set[str],
    ) -> None:
        classname = self.safe_name(classname)
        self.current_optional_fields = optional_fields
        self.current_fieldtypes: dict[str, TypeDef] = {}
        self.current_class_is_abstract = abstract

        if extends:
            ext = ", ".join(self.safe_name(e) for e in extends)
        else:
            ext = "Saveable"

        if self.current_class_is_abstract:
            ext += ", metaclass=ABCMeta"
            decorator = "@trait\n"
        else:
            decorator = ""

        self.out.write(fmt(f"{decorator}class {classname}({ext}):\n    pass", 0)[:-9])
        # make a valid class for Black, but then trim off the "pass"

        if doc:
            self.out.write(fmt(f'"""\n{doc}\n"""\n', 4) + "\n")

        self.serializer = StringIO()

        if self.current_class_is_abstract:
            return

        self.current_idfield: str | None = self.safe_name(idfield) if idfield != "" else None
        if self.current_idfield is not None:
            self.out.write(f"    {self.current_idfield}: str\n\n")

        field_eqs: Final = []
        field_hashes: Final = []
        for name in field_names:
            field_eqs.append("self.{0} == other.{0}".format(self.safe_name(name)))
            field_hashes.append(f"self.{self.safe_name(name)}")
        field_eq: Final = " and\n                    ".join(field_eqs)
        field_hash: Final = ",\n            ".join(field_hashes)
        self.out.write(
            fmt(
                f"""def __eq__(
    self,
    other: Any
) -> bool:
    if isinstance(other, {classname}):
        return bool({field_eq})
    return False
""",
                4,
            )
        )
        self.out.write(
            "\n"
            + fmt(
                f"""def __hash__(self) -> int:
    return hash((
        {field_hash}
    ))
""",
                4,
            )
        )

        self.out.write(
            """
    @classmethod
    def fromDoc(
        cls,
        doc: Any,
        baseuri: str,
        loadingOptions: LoadingOptions,
        docRoot: str | None = None
    ) -> Self:
        _doc = copy.copy(doc)

        if hasattr(doc, "lc"):
            _doc.lc.data = doc.lc.data
            _doc.lc.filename = doc.lc.filename
        _errors__ = []
"""  # noqa: B907
        )

        self.idfield = idfield

        self.serializer.write(
            """
    def save(
        self, top: bool = False, base_url: str = "", relative_uris: bool = True
    ) -> dict[str, Any]:
        r: dict[str, Any] = {}

        if relative_uris:
            for ef in self.extension_fields:
                r[prefix_url(ef, self.loadingOptions.vocab)] = self.extension_fields[ef]
        else:
            for ef in self.extension_fields:
                r[ef] = self.extension_fields[ef]
"""
        )

    def end_class(self, classname: str, field_names: list[str]) -> None:
        """Signal that we are done with this class."""
        if self.current_class_is_abstract:
            if field_names:
                for name in field_names:
                    safename = self.safe_name(name)
                    self.out.write(
                        f"    {safename}: {self.current_fieldtypes[safename].instance_type}\n"
                    )
                self.out.write("\n\n")
            else:
                self.out.write("    pass\n\n\n")
            return

        self.out.write(
            fmt(
                """
extension_fields: MutableMapping[str, Any] = {{}}
for k in _doc.keys():
    if k not in cls.attrs:
        if not k:
            _errors__.append(
                ValidationException("mapping with implicit null key")
            )
        elif ":" in k:
            ex = expand_url(
                k, "", loadingOptions, scoped_id=False, vocab_term=False
            )
            extension_fields[ex] = _doc[k]
        else:
            _errors__.append(
                ValidationException(
                    "invalid field `{{}}`, expected one of: {attrstr}".format(
                        k
                    ),
                    SourceLine(_doc, k, str),
                )
            )

if _errors__:
    raise ValidationException("", None, _errors__, "*")
""".format(
                    attrstr=", ".join([f"`{f}`" for f in field_names]),
                ),
                8,
            )
        )

        self.serializer.write(
            """
        # top refers to the directory level
        if top:
            if self.loadingOptions.namespaces:
                r["$namespaces"] = self.loadingOptions.namespaces
            if self.loadingOptions.schemas:
                r["$schemas"] = self.loadingOptions.schemas
"""
        )

        self.serializer.write("        return r\n")

        required_field_names: Final = [
            f for f in field_names if f not in self.current_optional_fields
        ]
        optional_field_names: Final = [f for f in field_names if f in self.current_optional_fields]

        idfield_safe_name: Final = (
            self.safe_name(self.current_idfield) if self.current_idfield is not None else None
        )
        safe_inits: Final[list[str]] = ["        self,"]
        safe_inits.extend(
            [
                f"        {self.safe_name(f)}: {self.current_fieldtypes[self.safe_name(f)].instance_type},"
                for f in required_field_names
                if f != "class"
            ]
        )
        safe_inits.extend(
            [
                f"        {self.safe_name(f)}: "
                f"{self.current_fieldtypes[self.safe_name(f)].instance_type} = None,"
                for f in optional_field_names
                if f != "class"
            ]
        )
        self.serializer.write(
            "\n    def __init__(\n"
            + "\n".join(safe_inits)
            + "\n        extension_fields: MutableMapping[str, Any] | None = None,"
            + "\n        loadingOptions: LoadingOptions | None = None,"
            + "\n    ) -> None:\n"
            + """        if extension_fields:
            self.extension_fields = extension_fields
        else:
            self.extension_fields = CommentedMap()
        if loadingOptions:
            self.loadingOptions = loadingOptions
        else:
            self.loadingOptions = LoadingOptions()
"""
        )
        field_inits = ""
        for name in field_names:
            if name == "class":
                field_inits += """        self.class_: Final[str] = "{}"
""".format(
                    self.safe_name(classname)
                )
            elif name == idfield_safe_name and name in optional_field_names:
                field_inits += (
                    "        self.{0}: str = {0} if {0} is not None else "
                    '"_:" + str(_uuid__.uuid4())\n'.format(self.safe_name(name))
                )
            else:
                field_inits += """        self.{0}: {1} = {0}
""".format(
                    self.safe_name(name),
                    self.current_fieldtypes[self.safe_name(name)].instance_type,
                )
        self.serializer.write(f"{field_inits}\n")

        self.serializer.write(
            fmt(
                f"""attrs: ClassVar[Collection[str]] = frozenset(["{'", "'.join(field_names)}"])\n""",  # noqa: B907
                4,
            )
        )

        safe_inits2: Final = []

        if self.current_idfield is not None:
            safe_inits2.append(f"{idfield_safe_name}=cast(str, {idfield_safe_name})")

        safe_inits2.extend(
            [
                f"{f}={f}"
                for f in (
                    self.safe_name(f)
                    for f in field_names
                    if f not in ("class", self.current_idfield)
                )
            ]
        )
        safe_inits2.extend(["extension_fields=extension_fields", "loadingOptions=loadingOptions"])

        self.out.write(
            "        _constructed = cls(\n            "
            + ",\n            ".join(safe_inits2)
            + ",\n        )\n"
        )
        if self.idfield:
            self.out.write(
                f"        loadingOptions.idx[cast(str, {self.safe_name(self.idfield)})] "
                "= (_constructed, loadingOptions)\n"
            )

        self.out.write("        return _constructed\n")

        self.out.write(str(self.serializer.getvalue()))

        self.out.write("\n\n")

    def type_loader(
        self,
        type_declaration: list[Any] | dict[str, Any] | str,
        container: str | None = None,
        no_link_check: bool | None = None,
    ) -> TypeDef:
        """Parse the given type declaration and declare its components."""
        match type_declaration:
            case MutableSequence():
                sub_types1: Final = [self.type_loader(i) for i in type_declaration]
                sub_names1: Final = [t.name for t in sub_types1]
                return self.declare_type(
                    TypeDef(
                        name="union_of_{}".format("_or_".join(sub_names1)),
                        init="_UnionLoader(({},))".format(", ".join(sub_names1)),
                        instance_type=" | ".join(
                            sorted({t.instance_type or "" for t in sub_types1})
                        ),
                    )
                )
            case {"type": "array" | "https://w3id.org/cwl/salad#array", "items": items}:
                i1: Final = self.type_loader(items)
                return self.declare_type(
                    TypeDef(
                        name=f"array_of_{i1.name}",
                        init=f"_ArrayLoader({i1.name})",
                        instance_type=f"Sequence[{i1.instance_type}]",
                    )
                )
            case {"type": "map" | "https://w3id.org/cwl/salad#map", "values": values, **rest}:
                i2: Final = self.type_loader(values)
                name = self.safe_name(str(rest["name"])) if "name" in rest else None
                anon_type = self.declare_type(
                    TypeDef(
                        name=f"map_of_{i2.name}",
                        init="_MapLoader({}, {}, {}, {})".format(
                            i2.name,
                            f"'{name}'",  # noqa: B907
                            f"'{container}'" if container is not None else None,  # noqa: B907
                            no_link_check,
                        ),
                        instance_type=f"Mapping[str, {i2.instance_type}]",
                    )
                )
                if "name" in rest:
                    return self.declare_type(
                        TypeDef(
                            name=self.safe_name(str(rest["name"])) + "Loader",
                            init=anon_type.name,
                            instance_type=anon_type.instance_type,
                        )
                    )
                else:
                    return anon_type
            case {
                "type": "enum" | "https://w3id.org/cwl/salad#enum",
                "symbols": symbols,
                "name": name,
                **rest,
            }:
                for sym in symbols:
                    self.add_vocab(shortname(sym), sym)
                if "doc" in rest:
                    doc: Final = rest["doc"]
                    if isinstance(doc, MutableSequence):
                        formated_doc = "\n".join(doc)
                    else:
                        formated_doc = str(doc).strip()
                    docstring = f'\n"""\n{formated_doc}\n"""'
                else:
                    docstring = ""
                sym_names: Final = [schema.avro_field_name(sym) for sym in symbols]
                sym_literals: Final = [f'"{s}"' for s in sym_names]
                return self.declare_type(
                    TypeDef(
                        name=self.safe_name(name) + "Loader",
                        init='_EnumLoader(("{}",), "{}"){}'.format(
                            '", "'.join(sym_names),
                            self.safe_name(name),
                            docstring,
                        ),
                        instance_type=f"Literal[{', '.join(sym_literals)}]",
                    )
                )

            case {"type": "record" | "https://w3id.org/cwl/salad#record", "name": name, **rest}:
                return self.declare_type(
                    TypeDef(
                        name=self.safe_name(name) + "Loader",
                        init="_RecordLoader({}, {}, {})".format(
                            self.safe_name(name),
                            f"'{container}'" if container is not None else None,  # noqa: B907
                            no_link_check,
                        ),
                        instance_type=self.safe_name(name),
                        abstract=bool(rest.get("abstract", False)),
                    )
                )

            case {
                "type": "union" | "https://w3id.org/cwl/salad#union",
                "name": name,
                "names": list(names),
            }:
                # Declare the named loader to handle recursive union definitions
                loader_name = self.safe_name(name) + "Loader"
                loader_type = TypeDef(
                    name=loader_name,
                    init=f"_UnionLoader((), '{loader_name}')",
                    instance_type=self.safe_name(name),
                )
                self.declare_type(loader_type)
                # Parse inner types
                sub_types2: Final = [self.type_loader(i) for i in names]
                sub_names2: Final = list(dict.fromkeys(t.name for t in sub_types2))
                # Register lazy initialization for the loader
                self.add_lazy_init(
                    LazyInitDef(
                        name=loader_name,
                        init="{}.add_loaders(({},))".format(loader_name, ", ".join(sub_names2)),
                        instance_type=f'{self.safe_name(name)}: TypeAlias = "'
                        + " | ".join(
                            sorted(
                                {t.instance_type for t in sub_types2 if t.instance_type is not None}
                            )
                        )
                        + '"',
                    )
                )
                return loader_type
            case {"type": decl}:
                raise SchemaException(f"wft {decl}")

            case str(decl) if decl in prims:
                return prims[decl]

            case "Expression" | "https://w3id.org/cwl/cwl#Expression" as decl:
                return self.declare_type(
                    TypeDef(
                        name=self.safe_name(decl) + "Loader",
                        init="_ExpressionLoader(str)",
                        instance_type="str",
                    )
                )
            case str(decl):
                return self.collected_types[self.safe_name(decl) + "Loader"]
            case _ as decl:
                raise SchemaException(f"wtf {decl}")

    def declare_id_field(
        self,
        name: str,
        fieldtype: TypeDef,
        doc: str | None,
        optional: bool,
    ) -> None:
        self.declare_field(name, fieldtype, doc, True, "")

        if self.current_class_is_abstract:
            return

        if optional:
            opt = """{safename} = "_:" + str(_uuid__.uuid4())""".format(
                safename=self.safe_name(name)
            )
        else:
            opt = """_errors__.append(ValidationException("missing {fieldname}"))""".format(
                fieldname=shortname(name)
            )

        self.out.write(
            """
        __original_{safename}_is_none = {safename} is None
        if {safename} is None:
            if docRoot is not None:
                {safename} = docRoot
            else:
                {opt}
        if not __original_{safename}_is_none:
            baseuri = cast(str, {safename})
""".format(
                safename=self.safe_name(name), opt=opt
            )
        )

    def declare_field(
        self,
        name: str,
        fieldtype: TypeDef,
        doc: str | None,
        optional: bool,
        subscope: str | None,
    ) -> None:
        self.current_fieldtypes[self.safe_name(name)] = fieldtype

        if self.current_class_is_abstract:
            return

        if optional:
            self.out.write(f"""        {self.safe_name(name)} = None\n""")
            self.out.write(f"""        if "{shortname(name)}" in _doc:\n""")  # noqa: B907
            spc = "    "
        else:
            spc = ""

        if subscope:
            self.out.write(
                """
{spc}        subscope_baseuri = expand_url('{subscope}', baseuri, loadingOptions, True)
""".format(
                    subscope=subscope, spc=spc
                )
            )
            baseurivar = "subscope_baseuri"
        else:
            baseurivar = "baseuri"

        self.out.write(
            f"""{spc}        try:
"""
        )

        if not optional:
            self.out.write(
                """{spc}            if _doc.get("{fieldname}") is None:
{spc}                raise ValidationException("missing required field `{fieldname}`", None, [])

""".format(
                    fieldname=shortname(name),
                    spc=spc,
                )
            )

        self.out.write(
            """{spc}            {safename} = load_field(
{spc}                _doc.get("{fieldname}"),
{spc}                {fieldtype},
{spc}                {baseurivar},
{spc}                loadingOptions,
{spc}                lc=_doc.get("{fieldname}")
{spc}            )
""".format(
                safename=self.safe_name(name),
                fieldname=shortname(name),
                fieldtype=fieldtype.name,
                baseurivar=baseurivar,
                spc=spc,
            )
        )

        if shortname(name) == "class":
            self.out.write(
                """
{spc}            if {safename} not in (cls.__name__, loadingOptions.vocab.get(cls.__name__)):
{spc}               raise ValidationException(f"tried `{{cls.__name__}}` but")
{spc}        except ValidationException as e:
{spc}               raise e
""".format(
                    safename=self.safe_name(name),
                    spc=spc,
                )
            )

        else:
            self.out.write(
                """
{spc}        except ValidationException as e:
{spc}            error_message, to_print, verb_tensage = parse_errors(str(e))

{spc}            if str(e) == "missing required field `{fieldname}`":
{spc}                _errors__.append(
{spc}                    ValidationException(
{spc}                        str(e),
{spc}                        None
{spc}                    )
{spc}                )
{spc}            else:
{spc}                val = _doc.get("{fieldname}")
{spc}                if error_message != str(e):
{spc}                    val_type = convert_typing(extract_type(type(val)))
{spc}                    _errors__.append(
{spc}                        ValidationException(
{spc}                            \"the `{fieldname}` field is not valid because:\",
{spc}                            SourceLine(_doc, "{fieldname}", str),
{spc}                            [ValidationException(f"Value is a {{val_type}}, "
{spc}                                                 f"but valid {{to_print}} for this field "
{spc}                                                 f"{{verb_tensage}} {{error_message}}",
{spc}                                                 detailed_message=f"Value `{{val}}` is a {{val_type}}, "
{spc}                                                 f"but valid {{to_print}} for this field "
{spc}                                                 f"{{verb_tensage}} {{error_message}}")],
{spc}                        )
{spc}                    )
{spc}                else:
{spc}                    _errors__.append(
{spc}                        ValidationException(
{spc}                            "the `{fieldname}` field is not valid because:",
{spc}                            SourceLine(_doc, "{fieldname}", str),
{spc}                            [e],
{spc}                            detailed_message=f"the `{fieldname}` field with value `{{val}}` "
{spc}                            "is not valid because:\",
{spc}                        )
{spc}                    )
""".format(
                    fieldname=shortname(name),
                    spc=spc,
                )
            )

        if name == self.idfield or not self.idfield:
            baseurl = "base_url"
        else:
            baseurl = f"self.{self.safe_name(self.idfield)}"

        if shortname(name) == "class":
            self.serializer.write(
                fmt(
                    """
if self.{safename} is not None:
    uri = self.loadingOptions.vocab[self.{safename}]
    if p := self.loadingOptions.rvocab.get(uri[:-len(self.{safename})]):
        uri = f"{{p}}:{{self.{safename}}}"
    else:
        uri = self.{safename}
    u = save_relative_uri(uri, {baseurl}, {scoped_id}, {ref_scope}, relative_uris)
    r["{fieldname}"] = u
""".format(
                        safename=self.safe_name(name),
                        fieldname=shortname(name).strip(),
                        baseurl=baseurl,
                        scoped_id=fieldtype.scoped_id,
                        ref_scope=fieldtype.ref_scope,
                    ),
                    8,
                )
            )
        elif fieldtype.is_uri:
            self.serializer.write(
                fmt(
                    """
if self.{safename} is not None:
    u = save_relative_uri(self.{safename}, {baseurl}, {scoped_id}, {ref_scope}, relative_uris)
    r["{fieldname}"] = u
""".format(
                        safename=self.safe_name(name),
                        fieldname=shortname(name).strip(),
                        baseurl=baseurl,
                        scoped_id=fieldtype.scoped_id,
                        ref_scope=fieldtype.ref_scope,
                    ),
                    8,
                )
            )
        else:
            self.serializer.write(
                fmt(
                    """
if self.{safename} is not None:
    r["{fieldname}"] = save(
        self.{safename}, top=False, base_url={baseurl}, relative_uris=relative_uris
    )
""".format(
                        safename=self.safe_name(name),
                        fieldname=shortname(name),
                        baseurl=baseurl,
                    ),
                    8,
                )
            )

    def uri_loader(
        self,
        inner: TypeDef,
        scoped_id: bool,
        vocab_term: bool,
        ref_scope: int | None,
        no_link_check: bool | None = None,
    ) -> TypeDef:
        """Construct the TypeDef for the given URI loader."""
        return self.declare_type(
            TypeDef(
                name=f"uri_{inner.name}_{scoped_id}_{vocab_term}_{ref_scope}_{no_link_check}",
                init=f"_URILoader({inner.name}, {scoped_id}, {vocab_term}, {ref_scope}, {no_link_check})",
                is_uri=True,
                scoped_id=scoped_id,
                ref_scope=ref_scope,
                instance_type=inner.instance_type,
            )
        )

    def idmap_loader(
        self, field: str, inner: TypeDef, map_subject: str, map_predicate: str | None
    ) -> TypeDef:
        """Construct the TypeDef for the given mapped ID loader."""
        return self.declare_type(
            TypeDef(
                name=f"idmap_{self.safe_name(field)}_{inner.name}",
                init=f"_IdMapLoader({inner.name}, '{map_subject}', '{map_predicate}')",  # noqa: B907
                instance_type=inner.instance_type,
            )
        )

    def typedsl_loader(self, inner: TypeDef, ref_scope: int | None) -> TypeDef:
        """Construct the TypeDef for the given DSL loader."""
        return self.declare_type(
            TypeDef(
                name=f"typedsl_{self.safe_name(inner.name)}_{ref_scope}",
                init=f"_TypeDSLLoader({self.safe_name(inner.name)}, {ref_scope}, "  # noqa: B907
                f"'{self.salad_version}')",  # noqa: B907
                instance_type=inner.instance_type,
            )
        )

    def secondaryfilesdsl_loader(self, inner: TypeDef) -> TypeDef:
        """Construct the TypeDef for secondary files."""
        return self.declare_type(
            TypeDef(
                name=f"secondaryfilesdsl_{inner.name}",
                init=f"_UnionLoader((_SecondaryDSLLoader({inner.name}), {inner.name},))",
                instance_type=inner.instance_type,
            )
        )

    def epilogue(self, root_loader: TypeDef) -> None:
        """Trigger to generate the epilouge code."""

        self.out.write("_vocab.update({\n")
        for k in sorted(self.vocab.keys()):
            self.out.write(f'    "{k}": "{self.vocab[k]}",\n')  # noqa: B907
        self.out.write("})\n")

        self.out.write("_rvocab.update({\n")
        for k in sorted(self.vocab.keys()):
            self.out.write(f'    "{self.vocab[k]}": "{k}",\n')  # noqa: B907
        self.out.write("})\n\n")

        for _, collected_type in self.collected_types.items():
            if not collected_type.abstract:
                self.out.write(fmt(f"{collected_type.name}: Final = {collected_type.init}\n", 0))
        self.out.write("\n")

        if self.lazy_inits:
            for lazy_init in self.lazy_inits.values():
                self.out.write(fmt(f"{lazy_init.init}\n", 0))
                self.out.write(fmt(f"{lazy_init.instance_type}", 0))
            self.out.write("\n")

        self.out.write(
            """
def load_document(
    doc: Any,
    baseuri: str | None = None,
    loadingOptions: LoadingOptions | None = None,
) -> Any:
    if baseuri is None:
        baseuri = file_uri(os.getcwd()) + "/"
    if loadingOptions is None:
        loadingOptions = LoadingOptions()
    result, metadata = _document_load(
        %(name)s,
        doc,
        baseuri,
        loadingOptions,
    )
    return result


def load_document_with_metadata(
    doc: Any,
    baseuri: str | None = None,
    loadingOptions: LoadingOptions | None = None,
    addl_metadata_fields: MutableSequence[str] | None = None,
) -> Any:
    if baseuri is None:
        baseuri = file_uri(os.getcwd()) + "/"
    if loadingOptions is None:
        loadingOptions = LoadingOptions(fileuri=baseuri)
    return _document_load(
        %(name)s,
        doc,
        baseuri,
        loadingOptions,
        addl_metadata_fields=addl_metadata_fields,
    )


def load_document_by_string(
    string: Any,
    uri: str,
    loadingOptions: LoadingOptions | None = None,
) -> Any:
    yaml = yaml_no_ts()
    result = yaml.load(string)
    add_lc_filename(result, uri)

    if loadingOptions is None:
        loadingOptions = LoadingOptions(fileuri=uri)

    result, metadata = _document_load(
        %(name)s,
        result,
        uri,
        loadingOptions,
    )
    return result


def load_document_by_yaml(
    yaml: Any,
    uri: str,
    loadingOptions: LoadingOptions | None = None,
) -> Any:
    """
            '"""'
            """
    Shortcut to load via a YAML object.
    yaml: must be from ruamel.yaml.main.YAML.load with preserve_quotes=True
    """
            '"""'
            """
    add_lc_filename(yaml, uri)

    if loadingOptions is None:
        loadingOptions = LoadingOptions(fileuri=uri)

    result, metadata = _document_load(
        %(name)s,
        yaml,
        uri,
        loadingOptions,
    )
    return result
"""
            % dict(name=root_loader.name)
        )
